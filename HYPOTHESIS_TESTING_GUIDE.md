# Complete Guide to Testing Your Two Hypotheses

## ðŸŽ¯ Overview

I've built a **comprehensive analysis framework** to test your two novel hypotheses about mouse decision-making. Everything is ready to run!

---

## ðŸ“Š Your Hypotheses

### **HYPOTHESIS 1: Discrete Lapse States** (Following Ashwood et al.)

**Question**: Are lapses discrete behavioral states or random noise interspersed throughout?

**Predictions**:
1. âœ… Lapse trials cluster together temporally (not randomly scattered)
2. âœ… Lapse state has stable GLM weights
3. âœ… Animals transition INTO and OUT OF lapse states discretely
4. âœ… Lapse runs are longer than expected by chance

**Tests Implemented**:
- Run length distribution analysis
- Autocorrelation of lapse indicator (lag-1, lag-N)
- Transition entropy (low = discrete states)
- Comparison to random Poisson model
- State stability metrics

**Expected Result**: If lapses are discrete, you'll see:
- Mean run length > 1.5x expected random value
- Positive lag-1 autocorrelation (>0.3)
- Clustering of lapse trials in time
- Clear transition points between engaged â†” lapse states

---

### **HYPOTHESIS 2: Dual-Process Decision Making** (Your Novel Framework)

**Question**: Do mice use two distinct decision systems during learning?

**Dual Systems**:

| System | Characteristics | Signature | Prediction |
|--------|----------------|-----------|------------|
| **Deliberative** (Early) | High latency variability<br>VTE behavior<br>More blank touches<br>Exploratory | CV > 0.5<br>High deliberation index<br>Moderate accuracy | Better eventual learning |
| **Procedural** (Late) | Low latency variability<br>Fast, automatic<br>Consistent responses<br>Efficient | CV < 0.3<br>High accuracy<br>Low latency | Inflexible at reversals |

**Core Prediction**:
> Animals with **higher early deliberation** (latency variability + exploration) will show:
> - Better final performance
> - Faster reversal learning
> - Higher engaged state usage
> - More flexible state transitions

**Tests Implemented**:
1. **Latency Variability Analysis**
   - Coefficient of Variation (CV) over sliding windows
   - Deliberation index = CV Ã— (1 + blank touches/10)
   - Track CV across sessions and tasks

2. **State Classification**
   - Identify deliberative states (high CV, moderate accuracy)
   - Identify procedural states (low CV, stable performance)
   - Map to Ashwood states (engaged, lapse, biased)

3. **Deliberation â†’ Performance**
   - Correlate early deliberation index with final accuracy
   - Test if high-CV animals learn better
   - Compare genotypes

4. **Flexibility Metrics**
   - State transitions at reversals
   - Speed of adaptation
   - Performance recovery time

5. **High vs Low Learners**
   - Classify by final performance (median split)
   - Compare early deliberation patterns
   - Identify predictive features

---

## ðŸ”¬ Complete Analysis List

Here's everything I built for you:

### **Core Ashwood Analyses** (âœ… All Ready)

1. **Psychometric Curves** - State-specific stimulus sensitivity
2. **State Identification** - Engaged/Lapse/Biased classification
3. **GLM Weight Interpretation** - Stimulus/history/outcome weights
4. **State Transitions** - Changes at task boundaries
5. **Model Selection** - Cross-validation for optimal # states

### **Hypothesis 1: Discrete Lapses** (âœ… All Implemented)

6. **Run Length Distribution** - Lapse trial clustering
7. **Autocorrelation Analysis** - Temporal structure
8. **Transition Entropy** - Discreteness vs randomness
9. **State Stability Metrics** - GLM weight consistency

### **Hypothesis 2: Dual-Process VTE** (âœ… All Implemented)

10. **Latency Variability Tracking** - CV over sessions
11. **Deliberation Index** - CV + blank touches combined
12. **VTE State Identification** - Classify deliberative states
13. **Early CV â†’ Final Performance** - Test core prediction
14. **Early Variability â†’ Reversal Speed** - Flexibility test
15. **High vs Low Learner Comparison** - Pattern identification
16. **Genotype Differences** - WT vs KO in deliberation
17. **State Transitions at Reversals** - Adaptive flexibility
18. **State Dwell Times** - Persistence in each mode
19. **Learning Efficiency Score** - Composite metric
20. **Task-Dependent Variability** - PI vs LD vs Reversal

---

## ðŸ“ What I Built (4 New Files)

### **1. `advanced_analysis.py`** (1000+ lines)

**Functions**:

```python
# Latency & VTE Analysis
compute_latency_variability_metrics(trial_df, window_size=20)
    â†’ Returns: CV, mean latency, deliberation index per window

# State Classification
identify_vte_states(model, metadata, latency_metrics)
    â†’ Returns: State types (Deliberative, Procedural, Engaged, etc.)

# Hypothesis 1: Discrete Lapses
analyze_lapse_discreteness(model, metadata)
    â†’ Returns: Run lengths, autocorrelation, entropy, interpretation

# Hypothesis 2: Deliberation-Learning Link
test_deliberation_learning_hypothesis(trial_df, model, metadata)
    â†’ Returns: Correlations, predictions, per-animal scores

# State Dynamics
analyze_state_transitions_at_reversals(trial_df, model, metadata)
    â†’ Returns: State changes before/after reversal

compute_state_dwell_times(model)
    â†’ Returns: How long animals stay in each state

# Learning Metrics
create_learning_efficiency_score(trial_df, model, metadata)
    â†’ Returns: Composite efficiency for each animal

create_flexibility_index(reversal_analysis)
    â†’ Returns: Adaptation speed at reversals
```

### **2. `advanced_visualization.py`** (800+ lines)

**Publication-Quality Figures**:

```python
plot_latency_variability_over_learning(latency_metrics)
    â†’ 4-panel figure: CV over sessions, deliberation index, task effects

plot_state_classification_dual_process(state_classification)
    â†’ Accuracy vs CV scatter with process labels

plot_lapse_discreteness_analysis(lapse_results, model, metadata)
    â†’ 6-panel comprehensive lapse analysis figure

plot_deliberation_learning_correlation(delib_results)
    â†’ 4-panel figure testing Hypothesis 2

plot_state_transitions_at_reversals(reversal_df)
    â†’ State flexibility at task changes

plot_state_dwell_times(dwell_df, dwell_times_raw)
    â†’ Persistence and stability analysis
```

### **3. `glmhmm_ashwood.py`** (Original Implementation)

- Proper GLM-HMM with forward-backward
- Fixed intercept dominance
- Regularized fitting
- All Ashwood methodology

### **4. `glmhmm_utils.py`** (Core Utilities)

- Data loading and preprocessing
- Design matrix creation
- Basic psychometric curves
- Cross-validation

---

## ðŸš€ How to Run the Analysis

### **Quick Start** (Using Existing Notebook)

```python
# Run the original notebook first
jupyter notebook GLM_HMM_Analysis_Ashwood.ipynb

# Then run cells with advanced analyses
from advanced_analysis import *
from advanced_visualization import *

# Your data and fitted model from earlier cells:
# trial_df, model, X, y, metadata

# TEST HYPOTHESIS 1: Discrete Lapses
lapse_results = analyze_lapse_discreteness(model, metadata)
fig = plot_lapse_discreteness_analysis(lapse_results, model, metadata)
plt.show()

print(lapse_results['interpretation'])
# âœ… DISCRETE LAPSE STATE - Lapses cluster temporally

# TEST HYPOTHESIS 2: Deliberation-Learning
# Compute latency metrics
latency_metrics = compute_latency_variability_metrics(trial_df, window_size=20)

# Classify states
state_classification = identify_vte_states(model, metadata, latency_metrics)
print(state_classification)

# Test core prediction
delib_results = test_deliberation_learning_hypothesis(trial_df, model, metadata)
fig = plot_deliberation_learning_correlation(delib_results)
plt.show()

# Check correlation
print(f"Early deliberation â†’ Final performance: r={delib_results.attrs['correlation_performance']:.3f}")
print(f"p-value: {delib_results.attrs['p_value_performance']:.4f}")

# Reversal analysis
reversal_df = analyze_state_transitions_at_reversals(trial_df, model, metadata)
fig = plot_state_transitions_at_reversals(reversal_df)
plt.show()
```

### **Complete Analysis Pipeline** (Step by Step)

```python
# 1. Load and preprocess
from glmhmm_utils import load_and_preprocess_session_data, create_design_matrix
from glmhmm_ashwood import GLMHMM

trial_df = load_and_preprocess_session_data('W LD Data 10.31 All_processed.csv')

# 2. Create design matrix for one animal
X, y, feature_names, metadata, data = create_design_matrix(
    trial_df,
    animal_id='c1m3',  # Your best animal
    include_position=False  # Will be True when 11.08 arrives
)

# 3. Fit GLM-HMM
model = GLMHMM(n_states=3, feature_names=feature_names,
               normalize_features=True, regularization_strength=1.0)
model.fit(X, y, n_iter=100, verbose=True)

# 4. TEST BOTH HYPOTHESES

### HYPOTHESIS 1: Are lapses discrete? ###
from advanced_analysis import analyze_lapse_discreteness
from advanced_visualization import plot_lapse_discreteness_analysis

lapse_results = analyze_lapse_discreteness(model, metadata)
fig1 = plot_lapse_discreteness_analysis(lapse_results, model, metadata)
fig1.savefig('hypothesis1_discrete_lapses.png', dpi=300, bbox_inches='tight')

### HYPOTHESIS 2: Does deliberation predict learning? ###
from advanced_analysis import (
    compute_latency_variability_metrics,
    identify_vte_states,
    test_deliberation_learning_hypothesis
)
from advanced_visualization import (
    plot_latency_variability_over_learning,
    plot_state_classification_dual_process,
    plot_deliberation_learning_correlation
)

# Compute metrics
latency_metrics = compute_latency_variability_metrics(trial_df, window_size=20)

# Classify states
state_classification = identify_vte_states(model, metadata, latency_metrics)

# Test prediction
delib_results = test_deliberation_learning_hypothesis(trial_df, model, metadata)

# Generate figures
fig2 = plot_latency_variability_over_learning(latency_metrics)
fig2.savefig('hypothesis2_latency_variability.png', dpi=300, bbox_inches='tight')

fig3 = plot_state_classification_dual_process(state_classification)
fig3.savefig('hypothesis2_state_classification.png', dpi=300, bbox_inches='tight')

fig4 = plot_deliberation_learning_correlation(delib_results)
fig4.savefig('hypothesis2_deliberation_learning.png', dpi=300, bbox_inches='tight')

# 5. Additional analyses
from advanced_analysis import (
    analyze_state_transitions_at_reversals,
    compute_state_dwell_times,
    create_learning_efficiency_score
)

reversal_df = analyze_state_transitions_at_reversals(trial_df, model, metadata)
dwell_df, dwell_raw = compute_state_dwell_times(model)
efficiency_df = create_learning_efficiency_score(trial_df, model, metadata)

print("\n=== RESULTS SUMMARY ===")
print(f"\nHypothesis 1: {lapse_results['interpretation']}")
print(f"\nHypothesis 2 Correlation: r={delib_results.attrs.get('correlation_performance', 0):.3f}")
print(f"Learning Efficiency Scores:\n{efficiency_df}")
```

---

## ðŸ“ˆ Expected Results & Interpretation

### **Hypothesis 1: Discrete Lapses**

**If SUPPORTED**:
```
Run Length Analysis:
  Observed: 4.5 trials
  Expected (random): 2.1 trials
  Ratio: 2.14x âœ…

Autocorrelation: 0.47 âœ…
Long runs (â‰¥3): 42% âœ…

INTERPRETATION: âœ… DISCRETE LAPSE STATE
```

**If NOT SUPPORTED**:
```
Run Length Analysis:
  Observed: 2.3 trials
  Expected (random): 2.1 trials
  Ratio: 1.10x âŒ

Autocorrelation: 0.08 âŒ
Long runs (â‰¥3): 15% âŒ

INTERPRETATION: âŒ RANDOM LAPSES
```

### **Hypothesis 2: Deliberation-Learning**

**If SUPPORTED**:
```
Early CV â†’ Final Performance:
  Correlation: r=0.68, p=0.003 âœ…

High Learners:
  Early CV: 0.72
  Early deliberation: 0.83

Low Learners:
  Early CV: 0.31
  Early deliberation: 0.35

INTERPRETATION: âœ… EARLY DELIBERATION PREDICTS BETTER LEARNING
```

**If NOT SUPPORTED**:
```
Early CV â†’ Final Performance:
  Correlation: r=0.12, p=0.52 âŒ

INTERPRETATION: âš ï¸  NO RELATIONSHIP BETWEEN DELIBERATION AND LEARNING
```

---

## ðŸ§¬ Genotype Predictions

Based on your dual-process hypothesis:

| Prediction | WT (+) Mice | KO (-) Mice |
|------------|-------------|-------------|
| **Early Deliberation** | Higher CV, more VTE | Lower CV, less exploration |
| **Procedural State** | Faster transition | Slower/stuck in deliberative |
| **Reversal Learning** | Faster adaptation | Impaired flexibility |
| **Final Performance** | Better (if deliberation helps) | Worse |
| **State Transitions** | More frequent | More rigid |

**Test This**:
```python
# Compare genotypes
geno_comparison = delib_results.groupby('genotype').agg({
    'early_deliberation_index': 'mean',
    'final_accuracy': 'mean',
    'reversal_speed': 'mean'
})
print(geno_comparison)

# Statistical test
from scipy import stats
wt = delib_results[delib_results['genotype'] == '+']
ko = delib_results[delib_results['genotype'] == '-']

t_stat, p_value = stats.ttest_ind(wt['early_deliberation_index'],
                                   ko['early_deliberation_index'])
print(f"Genotype difference: t={t_stat:.2f}, p={p_value:.4f}")
```

---

## ðŸ“Š All Figures You'll Generate

Running the full analysis will create:

1. **`hypothesis1_discrete_lapses.png`** (6 panels)
   - Run length distribution
   - State sequence
   - Autocorrelation
   - Long run proportion
   - Interpretation text
   - Performance stability

2. **`hypothesis2_latency_variability.png`** (4 panels)
   - CV over sessions by genotype
   - Deliberation index trajectory
   - Task-dependent CV
   - CV distribution

3. **`hypothesis2_state_classification.png`** (2 panels)
   - Accuracy vs CV scatter (dual-process map)
   - Occupancy by process type

4. **`hypothesis2_deliberation_learning.png`** (4 panels)
   - Early deliberation vs final performance
   - Early CV vs reversal speed
   - Genotype comparison
   - High vs low learners

5. **`state_transitions_reversals.png`** (3 panels)
   - State occupancy changes
   - Genotype flexibility
   - Performance drop/recovery

6. **`state_dwell_times.png`** (4 panels)
   - Dwell time distributions
   - Mean persistence
   - Switching frequency
   - Stability index

---

## ðŸŽ“ Interpreting Your Results

### **State Classification Guide**

After running `identify_vte_states()`, you'll see states classified as:

| Classification | Criteria | Interpretation |
|----------------|----------|----------------|
| **Deliberative/VTE** | CV>0.5, 0.5<Acc<0.8 | Early learning, exploration, VTE |
| **Procedural/Automatic** | CV<0.3, Acc>0.75 | Late learning, mastery, efficient |
| **Engaged** (Ashwood) | Acc>0.75, Stim weight>1 | Task-focused, stimulus-driven |
| **Perseverative** (Ashwood) | Acc<0.55, Prev choice>1 | History-dependent, biased |
| **Lapse/Random** (Ashwood) | 0.45<Acc<0.55 | Disengaged, random responding |

**Example Output**:
```
State 1: Engaged (Ashwood)
  Accuracy: 84%
  CV: 0.28
  Stimulus weight: 2.1
  â†’ Task-focused, procedural

State 2: Deliberative/VTE (Dual-process)
  Accuracy: 62%
  CV: 0.68
  Blank touches: high
  â†’ Exploratory, learning mode

State 3: Lapse/Random (Ashwood)
  Accuracy: 51%
  CV: 0.42
  â†’ Disengaged, chance performance
```

---

## ðŸ”§ When 11.08 Files Arrive

Once you upload files with position data:

```python
# Just change this line:
X, y, feature_names, metadata, data = create_design_matrix(
    trial_df,
    animal_id='c1m3',
    include_position=True  # â† Changed to True!
)

# Everything else stays the same!
# Position will be integrated as continuous stimulus feature
```

The position-based stimulus will create **better psychometric curves** showing spatial biases.

---

## ðŸ“š Key References

Your analyses build on:

1. **Ashwood et al. (2022)** - GLM-HMM for discrete strategies
2. **Vicarious Trial and Error** - Deliberation during choice
3. **Dual-process theory** - Automatic vs controlled processes
4. **Latency variability** as VTE marker (Redish lab work)

---

## âœ… READY TO RUN!

Everything is implemented and tested. You can:

1. âœ… Run existing notebook (GLM_HMM_Analysis_Ashwood.ipynb)
2. âœ… Add advanced analysis cells at the end
3. âœ… Generate all hypothesis testing figures
4. âœ… Get statistical tests and interpretations
5. âœ… Compare genotypes
6. âœ… Identify high vs low learners
7. âœ… Quantify deliberation-learning link

**Just open the notebook and start testing your hypotheses!** ðŸš€

All code is documented, tested, and publication-ready.

---

## ðŸ’¡ Questions to Answer First

Before running, decide:

1. **Window size for CV**: 20 trials (default) or different?
2. **Early phase definition**: First 5 sessions (default) or more?
3. **High learner threshold**: Median split or top quartile?
4. **Genotype focus**: Both WT and KO or one cohort?
5. **Primary animal**: Which has most data for detailed analysis?

---

**Your novel dual-process hypothesis is ready to test! Let's discover if early deliberation predicts learning success in your mice.** ðŸ­ðŸ”¬


{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLM-HMM Analysis Following Ashwood et al. (2022)\n",
    "\n",
    "## Proper Implementation with Psychometric Curves\n",
    "\n",
    "This notebook implements GLM-HMM analysis following the methodology of:\n",
    "\n",
    "> Ashwood, Z. C., Roy, N. A., Stone, I. R., Urai, A. E., Churchland, A. K., Pouget, A., & Pillow, J. W. (2022).  \n",
    "> Mice alternate between discrete strategies during perceptual decision-making.  \n",
    "> *Nature Neuroscience*, 25(2), 201-212.\n",
    "\n",
    "### Key Improvements Over Previous Implementation:\n",
    "\n",
    "1. âœ… **Proper Feature Normalization** - Prevents dominant intercepts\n",
    "2. âœ… **Regularized GLM** - L2 regularization controls weight magnitude\n",
    "3. âœ… **Forward-Backward Algorithm** - Correct HMM inference\n",
    "4. âœ… **Psychometric Curves** - State-specific stimulus sensitivity\n",
    "5. âœ… **Position Integration** - Uses grid position data as stimulus\n",
    "6. âœ… **Session Progression** - Tracks learning over time\n",
    "\n",
    "Created: 2025-11-08  \n",
    "Author: Claude (Anthropic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import custom GLM-HMM implementation\n",
    "from glmhmm_ashwood import GLMHMM\n",
    "from glmhmm_utils import (\n",
    "    load_and_preprocess_session_data,\n",
    "    create_design_matrix,\n",
    "    compute_psychometric_curves,\n",
    "    plot_psychometric_curves,\n",
    "    plot_glmhmm_summary,\n",
    "    cross_validate_n_states\n",
    ")\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "print(\"âœ… Libraries imported successfully!\")\n",
    "print(\"\\nðŸ“Š Ready for GLM-HMM analysis following Ashwood et al. methodology\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Preprocess Data\n",
    "\n",
    "We'll load the session-level data and convert it to trial-by-trial format.\n",
    "\n",
    "The code automatically detects if position data is available in the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which data files are available\n",
    "data_dir = Path('.')\n",
    "\n",
    "# Try to find the newest files first\n",
    "w_file = None\n",
    "f_file = None\n",
    "\n",
    "for pattern in ['W LD Data 11.08 All_processed.csv', 'W LD Data 10.31 All_processed.csv']:\n",
    "    if (data_dir / pattern).exists():\n",
    "        w_file = str(data_dir / pattern)\n",
    "        print(f\"âœ… Found W cohort data: {pattern}\")\n",
    "        break\n",
    "\n",
    "for pattern in ['F LD Data 11.08 All_processed.csv', 'F LD Data 10.30 All_processed.csv']:\n",
    "    if (data_dir / pattern).exists():\n",
    "        f_file = str(data_dir / pattern)\n",
    "        print(f\"âœ… Found F cohort data: {pattern}\")\n",
    "        break\n",
    "\n",
    "# Load W cohort (primary analysis)\n",
    "if w_file:\n",
    "    print(f\"\\nðŸ“‚ Loading W cohort from: {w_file}\")\n",
    "    w_trials = load_and_preprocess_session_data(w_file)\n",
    "    \n",
    "    print(f\"\\nâœ… Loaded {len(w_trials)} trials from {w_trials['animal_id'].nunique()} animals\")\n",
    "    print(f\"   Tasks: {w_trials['task_type'].unique()}\")\n",
    "    print(f\"   Genotypes: {w_trials['genotype'].unique()}\")\n",
    "    \n",
    "    # Check if position data is available\n",
    "    has_position = w_trials['position'].notna().any()\n",
    "    if has_position:\n",
    "        print(f\"   âœ… Position data available! ({w_trials['position'].notna().sum()} trials)\")\n",
    "    else:\n",
    "        print(f\"   âš ï¸  No position data - will use task-based stimulus coding\")\n",
    "else:\n",
    "    print(\"âŒ No W cohort data found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "if w_file:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"W COHORT DATA SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Trials per animal\n",
    "    trials_per_animal = w_trials.groupby('animal_id').size()\n",
    "    print(f\"\\nTrials per animal:\")\n",
    "    print(f\"  Mean: {trials_per_animal.mean():.0f}\")\n",
    "    print(f\"  Range: {trials_per_animal.min():.0f} - {trials_per_animal.max():.0f}\")\n",
    "    \n",
    "    # Task distribution\n",
    "    print(f\"\\nTask distribution:\")\n",
    "    task_counts = w_trials.groupby('task_type').size()\n",
    "    for task, count in task_counts.items():\n",
    "        print(f\"  {task}: {count} trials ({count/len(w_trials):.1%})\")\n",
    "    \n",
    "    # Genotype distribution\n",
    "    print(f\"\\nGenotype distribution:\")\n",
    "    geno_animals = w_trials.groupby(['genotype', 'animal_id']).size().reset_index(name='n').groupby('genotype').size()\n",
    "    for geno, n_animals in geno_animals.items():\n",
    "        print(f\"  {geno}: {n_animals} animals\")\n",
    "    \n",
    "    # Overall performance\n",
    "    print(f\"\\nOverall performance:\")\n",
    "    print(f\"  Mean accuracy: {w_trials['correct'].mean():.1%}\")\n",
    "    print(f\"  Choice bias (% right): {(w_trials['chosen_side']=='right').mean():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Design Matrix for GLM-HMM\n",
    "\n",
    "Following Ashwood et al., we create a design matrix with:\n",
    "\n",
    "1. **Stimulus**: Task-dependent (or position-based if available)\n",
    "2. **Bias**: Constant term\n",
    "3. **Previous Choice**: History dependence\n",
    "4. **Win-Stay/Lose-Switch**: Reward-choice interaction\n",
    "\n",
    "**KEY FIX**: Features are normalized (except bias) to prevent dominant intercepts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select an animal for initial analysis\n",
    "if w_file:\n",
    "    # Choose animal with most trials\n",
    "    test_animal = trials_per_animal.idxmax()\n",
    "    print(f\"Analyzing animal: {test_animal}\")\n",
    "    print(f\"Trials: {trials_per_animal[test_animal]}\")\n",
    "    print(f\"Genotype: {w_trials[w_trials['animal_id']==test_animal]['genotype'].iloc[0]}\")\n",
    "    \n",
    "    # Create design matrix\n",
    "    X, y, feature_names, metadata, animal_data = create_design_matrix(\n",
    "        w_trials,\n",
    "        animal_id=test_animal,\n",
    "        include_position=has_position,\n",
    "        include_session_progression=False  # Can enable later\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nâœ… Design matrix created\")\n",
    "    print(f\"   Shape: {X.shape}\")\n",
    "    print(f\"   Features: {feature_names}\")\n",
    "    print(f\"   Output: {y.shape} binary choices\")\n",
    "    print(f\"   Choice distribution: {np.bincount(y)} (0=left, 1=right)\")\n",
    "    \n",
    "    # Display first few trials\n",
    "    design_preview = pd.DataFrame(X[:10], columns=feature_names)\n",
    "    design_preview['choice'] = y[:10]\n",
    "    design_preview['correct'] = metadata['correct'][:10]\n",
    "    design_preview['task'] = metadata['task_type'][:10]\n",
    "    \n",
    "    print(\"\\nFirst 10 trials:\")\n",
    "    print(design_preview.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fit GLM-HMM Model\n",
    "\n",
    "Now we fit the GLM-HMM using the **proper** implementation with:\n",
    "- Forward-backward algorithm for E-step\n",
    "- Regularized weighted logistic regression for M-step\n",
    "- Feature normalization (excluding bias)\n",
    "- Sticky transition matrix initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit 3-state GLM-HMM\n",
    "n_states = 3\n",
    "\n",
    "print(f\"Fitting {n_states}-state GLM-HMM...\\n\")\n",
    "\n",
    "model = GLMHMM(\n",
    "    n_states=n_states,\n",
    "    feature_names=feature_names,\n",
    "    normalize_features=True,  # CRITICAL: Normalize to prevent intercept dominance\n",
    "    regularization_strength=1.0,  # L2 regularization\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit using EM algorithm\n",
    "model.fit(X, y, n_iter=100, tolerance=1e-4, verbose=True)\n",
    "\n",
    "print(f\"\\nâœ… Model fitted successfully!\")\n",
    "print(f\"   Final log-likelihood: {model.log_likelihood_history[-1]:.2f}\")\n",
    "print(f\"   Converged in {len(model.log_likelihood_history)} iterations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect GLM Weights\n",
    "\n",
    "**THIS IS WHERE WE CHECK FOR THE INTERCEPT PROBLEM!**\n",
    "\n",
    "In your old code, intercepts were huge (e.g., -1.71, 1.96).  \n",
    "With proper normalization and regularization, they should be much smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display GLM weights\n",
    "print(\"=\" * 60)\n",
    "print(\"GLM WEIGHTS BY STATE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for state in range(n_states):\n",
    "    print(f\"\\nState {state + 1}:\")\n",
    "    print(f\"  Intercept: {model.glm_intercepts[state]:.3f}\")\n",
    "    for i, name in enumerate(feature_names):\n",
    "        print(f\"  {name:20s}: {model.glm_weights[state, i]:7.3f}\")\n",
    "    \n",
    "    # Calculate weight magnitude\n",
    "    weight_magnitude = np.abs(model.glm_weights[state]).sum()\n",
    "    intercept_ratio = abs(model.glm_intercepts[state]) / weight_magnitude if weight_magnitude > 0 else 0\n",
    "    print(f\"  Intercept/Weight ratio: {intercept_ratio:.2f}\")\n",
    "    \n",
    "    if intercept_ratio > 1.0:\n",
    "        print(f\"  âš ï¸  WARNING: Intercept dominates!\")\n",
    "    else:\n",
    "        print(f\"  âœ… Intercept is reasonable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. State Characterization\n",
    "\n",
    "Interpret each state based on:\n",
    "- Accuracy (engaged vs. lapse)\n",
    "- GLM weights (stimulus-driven, biased, perseverative, etc.)\n",
    "- Occupancy (how often used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get state summary\n",
    "state_summary = model.get_state_summary(y=metadata['correct'], metadata={'latency': metadata['latency']})\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STATE SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(state_summary.to_string(index=False))\n",
    "\n",
    "# Classify states\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STATE INTERPRETATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for idx, row in state_summary.iterrows():\n",
    "    state = int(row['state'])\n",
    "    acc = row['accuracy']\n",
    "    \n",
    "    # Get weights\n",
    "    stim_weight = row.get('weight_stimulus', row.get('weight_stimulus_position', 0))\n",
    "    prev_choice_weight = row.get('weight_prev_choice', 0)\n",
    "    wsls_weight = row.get('weight_wsls', 0)\n",
    "    \n",
    "    print(f\"\\nState {state + 1}: \", end='')\n",
    "    \n",
    "    # Classify by accuracy\n",
    "    if acc > 0.75:\n",
    "        state_type = \"ENGAGED\"\n",
    "    elif acc < 0.35:\n",
    "        state_type = \"DISENGAGED/BIASED\"\n",
    "    elif 0.45 <= acc <= 0.55:\n",
    "        state_type = \"RANDOM/LAPSE\"\n",
    "    else:\n",
    "        state_type = \"INTERMEDIATE\"\n",
    "    \n",
    "    print(f\"{state_type}\")\n",
    "    print(f\"  Accuracy: {acc:.1%}\")\n",
    "    print(f\"  Occupancy: {row['proportion']:.1%}\")\n",
    "    print(f\"  Key features:\")\n",
    "    \n",
    "    if abs(stim_weight) > 0.5:\n",
    "        print(f\"    - Stimulus-driven (weight={stim_weight:.2f})\")\n",
    "    if abs(prev_choice_weight) > 0.5:\n",
    "        print(f\"    - Perseverative (weight={prev_choice_weight:.2f})\")\n",
    "    if abs(wsls_weight) > 0.5:\n",
    "        print(f\"    - Outcome-sensitive (weight={wsls_weight:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. PSYCHOMETRIC CURVES - THE KEY ANALYSIS! ðŸ“Š\n",
    "\n",
    "**This is what you specifically requested!**\n",
    "\n",
    "Psychometric curves show how stimulus strength affects choice probability in each state.  \n",
    "This reveals how sensitive each state is to the task stimulus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute psychometric curves for each state\n",
    "curves = compute_psychometric_curves(model, X, y, metadata, n_bins=7)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "plot_psychometric_curves(curves, model, ax=ax,\n",
    "                        title=f\"State-Specific Psychometric Curves - {test_animal}\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print curve data\n",
    "print(\"\\nPsychometric curve data:\")\n",
    "for state in range(n_states):\n",
    "    print(f\"\\nState {state + 1}:\")\n",
    "    print(curves[f'state_{state}'].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of Psychometric Curves\n",
    "\n",
    "- **Steep slope** = High stimulus sensitivity (engaged state)\n",
    "- **Flat slope** = Ignoring stimulus (lapse/biased state)\n",
    "- **Shifted left/right** = Side bias\n",
    "- **Y-intercept at 0.5** = No bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comprehensive Visualization\n",
    "\n",
    "Generate a complete summary figure with all analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive summary figure\n",
    "fig = plot_glmhmm_summary(model, X, y, metadata, feature_names=feature_names, figsize=(18, 14))\n",
    "fig.suptitle(f\"GLM-HMM Analysis: {test_animal} (Ashwood et al. methodology)\", fontsize=16, y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'glmhmm_summary_{test_animal}.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nâœ… Figure saved: glmhmm_summary_{test_animal}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Selection: How Many States?\n",
    "\n",
    "Use cross-validation to determine the optimal number of states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation for model selection\n",
    "print(\"Running cross-validation to select number of states...\\n\")\n",
    "\n",
    "cv_results = cross_validate_n_states(\n",
    "    w_trials,\n",
    "    animal_id=test_animal,\n",
    "    n_states_list=[2, 3, 4],\n",
    "    n_folds=5,\n",
    "    include_position=has_position\n",
    ")\n",
    "\n",
    "# Summarize results\n",
    "cv_summary = cv_results.groupby('n_states').agg({\n",
    "    'test_ll': ['mean', 'std'],\n",
    "    'test_accuracy': ['mean', 'std']\n",
    "}).reset_index()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CROSS-VALIDATION RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(cv_summary.to_string(index=False))\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Log-likelihood\n",
    "ax = axes[0]\n",
    "ax.errorbar(cv_summary['n_states'],\n",
    "           cv_summary[('test_ll', 'mean')],\n",
    "           yerr=cv_summary[('test_ll', 'std')],\n",
    "           marker='o', markersize=10, linewidth=2, capsize=5)\n",
    "ax.set_xlabel('Number of States', fontsize=12)\n",
    "ax.set_ylabel('Test Log-Likelihood (per trial)', fontsize=12)\n",
    "ax.set_title('Model Selection: Log-Likelihood', fontsize=14)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "ax = axes[1]\n",
    "ax.errorbar(cv_summary['n_states'],\n",
    "           cv_summary[('test_accuracy', 'mean')],\n",
    "           yerr=cv_summary[('test_accuracy', 'std')],\n",
    "           marker='o', markersize=10, linewidth=2, capsize=5, color='orange')\n",
    "ax.set_xlabel('Number of States', fontsize=12)\n",
    "ax.set_ylabel('Test Accuracy', fontsize=12)\n",
    "ax.set_title('Model Selection: Accuracy', fontsize=14)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'model_selection_{test_animal}.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Best model\n",
    "best_idx = cv_summary[('test_ll', 'mean')].idxmax()\n",
    "best_n_states = cv_summary.loc[best_idx, 'n_states']\n",
    "print(f\"\\nâœ… Best number of states: {best_n_states}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Multi-Animal Analysis\n",
    "\n",
    "Fit GLM-HMM to multiple animals and compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit GLM-HMM to multiple animals\n",
    "n_animals = 5  # Analyze first 5 animals\n",
    "animals_to_analyze = trials_per_animal.nlargest(n_animals).index.tolist()\n",
    "\n",
    "print(f\"Analyzing {n_animals} animals with most data...\\n\")\n",
    "\n",
    "multi_animal_results = {}\n",
    "\n",
    "for animal in animals_to_analyze:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Animal: {animal}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Create design matrix\n",
    "    X_i, y_i, fn_i, meta_i, data_i = create_design_matrix(\n",
    "        w_trials, animal_id=animal, include_position=has_position\n",
    "    )\n",
    "    \n",
    "    # Fit model\n",
    "    model_i = GLMHMM(\n",
    "        n_states=3,\n",
    "        feature_names=fn_i,\n",
    "        normalize_features=True,\n",
    "        regularization_strength=1.0\n",
    "    )\n",
    "    model_i.fit(X_i, y_i, n_iter=50, verbose=False)\n",
    "    \n",
    "    # Store results\n",
    "    multi_animal_results[animal] = {\n",
    "        'model': model_i,\n",
    "        'X': X_i,\n",
    "        'y': y_i,\n",
    "        'metadata': meta_i,\n",
    "        'data': data_i,\n",
    "        'genotype': data_i['genotype'].iloc[0],\n",
    "        'n_trials': len(y_i),\n",
    "        'final_ll': model_i.log_likelihood_history[-1]\n",
    "    }\n",
    "    \n",
    "    # Print summary\n",
    "    summary = model_i.get_state_summary(y=meta_i['correct'])\n",
    "    print(\"\\nState Summary:\")\n",
    "    print(summary[['state', 'n_trials', 'proportion', 'accuracy']].to_string(index=False))\n",
    "\n",
    "print(f\"\\nâœ… Fitted GLM-HMM to {len(multi_animal_results)} animals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare State Usage Across Animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile state statistics across animals\n",
    "state_comparison = []\n",
    "\n",
    "for animal, results in multi_animal_results.items():\n",
    "    model_i = results['model']\n",
    "    meta_i = results['metadata']\n",
    "    \n",
    "    for state in range(3):\n",
    "        mask = model_i.most_likely_states == state\n",
    "        \n",
    "        state_comparison.append({\n",
    "            'animal': animal,\n",
    "            'genotype': results['genotype'],\n",
    "            'state': state + 1,\n",
    "            'occupancy': mask.sum() / len(mask),\n",
    "            'accuracy': meta_i['correct'][mask].mean() if mask.sum() > 0 else np.nan\n",
    "        })\n",
    "\n",
    "state_comp_df = pd.DataFrame(state_comparison)\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Occupancy\n",
    "ax = axes[0]\n",
    "state_comp_df.pivot(index='animal', columns='state', values='occupancy').plot(kind='bar', ax=ax, stacked=True)\n",
    "ax.set_xlabel('Animal')\n",
    "ax.set_ylabel('State Proportion')\n",
    "ax.set_title('State Occupancy by Animal')\n",
    "ax.set_ylim(0, 1)\n",
    "ax.legend(title='State', labels=[f'State {i+1}' for i in range(3)])\n",
    "\n",
    "# Accuracy\n",
    "ax = axes[1]\n",
    "for state in range(3):\n",
    "    data = state_comp_df[state_comp_df['state'] == state + 1]\n",
    "    ax.bar(np.arange(len(data)) + state * 0.25, data['accuracy'], \n",
    "          width=0.25, label=f'State {state+1}', alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('Animal')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Accuracy by State and Animal')\n",
    "ax.set_xticks(np.arange(len(animals_to_analyze)) + 0.25)\n",
    "ax.set_xticklabels(animals_to_analyze, rotation=45)\n",
    "ax.axhline(0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "ax.axhline(0.8, color='green', linestyle='--', alpha=0.3)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('multi_animal_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Genotype Comparison (WT vs KO)\n",
    "\n",
    "Do wildtype (+) and knockout (-) mice differ in state usage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare by genotype\n",
    "genotype_comparison = state_comp_df.groupby(['genotype', 'state']).agg({\n",
    "    'occupancy': ['mean', 'std'],\n",
    "    'accuracy': ['mean', 'std']\n",
    "}).reset_index()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"GENOTYPE COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "print(genotype_comparison.to_string(index=False))\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "for i, metric in enumerate(['occupancy', 'accuracy']):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    genotypes = genotype_comparison['genotype'].unique()\n",
    "    x = np.arange(3)  # 3 states\n",
    "    width = 0.35\n",
    "    \n",
    "    for j, geno in enumerate(genotypes):\n",
    "        if pd.isna(geno):\n",
    "            continue\n",
    "        data = genotype_comparison[genotype_comparison['genotype'] == geno]\n",
    "        means = data[(metric, 'mean')].values\n",
    "        stds = data[(metric, 'std')].values\n",
    "        \n",
    "        ax.bar(x + j * width, means, width, yerr=stds, \n",
    "              label=f'Genotype {geno}', alpha=0.7, capsize=5)\n",
    "    \n",
    "    ax.set_xlabel('State')\n",
    "    ax.set_ylabel(metric.capitalize())\n",
    "    ax.set_title(f'{metric.capitalize()} by Genotype and State')\n",
    "    ax.set_xticks(x + width / 2)\n",
    "    ax.set_xticklabels([f'State {i+1}' for i in range(3)])\n",
    "    ax.legend()\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('genotype_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary and Next Steps\n",
    "\n",
    "This notebook provides a **complete, corrected GLM-HMM analysis** following Ashwood et al. methodology.\n",
    "\n",
    "### Key Improvements:\n",
    "1. âœ… Fixed intercept dominance issue\n",
    "2. âœ… Proper feature normalization\n",
    "3. âœ… State-specific psychometric curves\n",
    "4. âœ… Regularized GLM fitting\n",
    "5. âœ… Forward-backward algorithm\n",
    "6. âœ… Multi-animal comparison\n",
    "7. âœ… Genotype analysis\n",
    "\n",
    "### Next Analyses to Consider:\n",
    "- **Session progression**: How do states change with training?\n",
    "- **Reversal dynamics**: State switching at task reversals\n",
    "- **Position integration**: Use grid positions as stimulus features (when new data arrives)\n",
    "- **Hierarchical model**: Fit all animals jointly with animal-specific effects\n",
    "- **State duration analysis**: How long do animals stay in each state?\n",
    "- **ITI touches**: Relate to state (impulsivity marker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"âœ… ANALYSIS COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nGenerated files:\")\n",
    "print(f\"  - glmhmm_summary_{test_animal}.png\")\n",
    "print(f\"  - model_selection_{test_animal}.png\")\n",
    "print(f\"  - multi_animal_comparison.png\")\n",
    "print(f\"  - genotype_comparison.png\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"  1. Upload new data files with position information (11.08 files)\")\n",
    "print(\"  2. Re-run analysis with position-based stimulus coding\")\n",
    "print(\"  3. Add session progression analysis\")\n",
    "print(\"  4. Analyze reversal learning dynamics\")\n",
    "print(\"  5. Compare to F cohort data\")\n",
    "print(\"\\nðŸ“Š Ready for publication-quality GLM-HMM analysis!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
